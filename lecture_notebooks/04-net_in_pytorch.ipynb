{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/os/anaconda/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['step']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch introduction\n",
    "\n",
    "(Py)Torch is a neural network package developed by Facebook, that is extremely simple. We'll use it to implement neural networks\n",
    "\n",
    "# Torch tensor\n",
    "\n",
    "Torch tensors are just like numpy arrays, but with a twist - they can also live on the GPU. Many methods are called similarly to numpy's, but unfortunately there are many API differences. See the documentation for supported functions: http://pytorch.org/docs/master/tensors.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use torch.form_numpy to convert a numpy array. For CPU tensors, it is fast (no memory copy)\n",
    "\n",
    "# Define 4 samples\n",
    "X = torch.from_numpy(np.array([[0,0],\n",
    "                               [0,1],\n",
    "                               [1,0],\n",
    "                               [1,1]], dtype=np.float32))\n",
    "Y = torch.from_numpy(np.array([[0], [1],[1], [0]], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0\n",
      " 0  1\n",
      " 1  0\n",
      " 1  1\n",
      "[torch.FloatTensor of size 4x2]\n",
      " \n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7ff9a09f3e50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEICAYAAAC01Po2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXyr5E5vIg64AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9a305e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use tensor.numpy to turn a tensor into a numpy array - on CPU, this is fast (no memory copy)\n",
    "scatter(X.numpy()[:,0], X.numpy()[:,1], c=Y.numpy())\n",
    "axis('square')\n",
    "title('The XOR function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hW:  \n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      " hb:  \n",
      "-0.5000 -1.5000\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n",
      "H:  \n",
      " 0.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  1.0000\n",
      "[torch.FloatTensor of size 4x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define two neurons: an AND neuron, and an OR neuron\n",
    "hW = torch.from_numpy(np.array([[1.0, 1.0],\n",
    "                                [1.0, 1.0]], dtype=np.float32))\n",
    "hb = torch.from_numpy(np.array([[-.5, -1.5]], dtype=np.float32))\n",
    "\n",
    "print('hW: ', hW, 'hb: ', hb)\n",
    "\n",
    "# compute the hidden activation, we multiply by 10. to have the sigmoid look like the step function\n",
    "H = torch.sigmoid(100 * (X.matmul(hW) + hb))\n",
    "\n",
    "print('H: ', H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:  \n",
      " 1.9287e-22\n",
      " 1.0000e+00\n",
      " 1.0000e+00\n",
      " 1.9287e-22\n",
      "[torch.FloatTensor of size 4x1]\n",
      " Y:  \n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an output neuron (x1 OR x2) AND NOT (x1 AND x2)\n",
    "\n",
    "oW = torch.from_numpy(np.array([[ 1.0], \n",
    "                                [-1.0]], dtype=np.float32))\n",
    "ob = torch.from_numpy(np.array([[-0.5]], dtype=np.float32))\n",
    "\n",
    "# compute the output, we multiply by 10. to have the sigmoid look like the step function\n",
    "O = torch.sigmoid(100.0 * (H.matmul(oW) + ob))\n",
    "\n",
    "print('O: ', O, 'Y: ', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0072\n",
       " 0.9924\n",
       " 0.9924\n",
       " 0.0072\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's define a function\n",
    "\n",
    "def net(X, hW, hb, oW, ob):\n",
    "    H = torch.sigmoid(10.0 * (X.matmul(hW) + hb))\n",
    "    O = torch.sigmoid(10.0 * (H.matmul(oW) + ob))\n",
    "    return O\n",
    "\n",
    "net(X, hW, hb, oW, ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0\n",
       " 0  1\n",
       " 1  0\n",
       " 1  1\n",
       "[torch.cuda.FloatTensor of size 4x2 (GPU 0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0072\n",
       " 0.9924\n",
       " 0.9924\n",
       " 0.0072\n",
       "[torch.cuda.FloatTensor of size 4x1 (GPU 0)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA computations\n",
    "# Use .cuda() to move variable to the GPU\n",
    "\n",
    "net(X.cuda(), hW.cuda(), hb.cuda(), oW.cuda(), ob.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Variable class know about gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XV:  Variable containing:\n",
      " 0  0\n",
      " 0  1\n",
      " 1  0\n",
      " 1  1\n",
      "[torch.cuda.FloatTensor of size 4x2 (GPU 0)]\n",
      "\n",
      "XV.data:  \n",
      " 0  0\n",
      " 0  1\n",
      " 1  0\n",
      " 1  1\n",
      "[torch.cuda.FloatTensor of size 4x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XV = Variable(X.cuda(), requires_grad=False)\n",
    "\n",
    "# .data holds the values\n",
    "print(\"XV: \", XV)\n",
    "print(\"XV.data: \", XV.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out Variable containing:\n",
      " 0.0072\n",
      " 0.9924\n",
      " 0.9924\n",
      " 0.0072\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XV = Variable(X, requires_grad=False)\n",
    "YV = Variable(Y, requires_grad=False)\n",
    "\n",
    "hWV = Variable(hW, requires_grad=True)\n",
    "hbV = Variable(hb, requires_grad=True)\n",
    "oWV = Variable(oW, requires_grad=True)\n",
    "obV = Variable(ob, requires_grad=True)\n",
    "\n",
    "# notice that out will also be a variable\n",
    "out = net(XV, hWV, hbV, oWV, obV)\n",
    "print (\"out\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-04 *\n",
       "  2.1919\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ((out - YV)**2).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  \n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "grad:  Variable containing:\n",
      "1.00000e-05 *\n",
      " -7.7096  0.9561\n",
      " -7.7096  0.9561\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .data holds the values\n",
    "print(\"data: \", hWV.data)\n",
    "\n",
    "# .grad holds the accumulated grdient, but \n",
    "print(\"grad: \", hWV.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.00223529339\n",
      "250 0.0633510798216\n",
      "500 0.0106800086796\n",
      "750 0.00550934765488\n",
      "1000 0.0036630590912\n",
      "1250 0.00272816722281\n",
      "1500 0.00216689356603\n",
      "1750 0.00179384509102\n",
      "2000 0.00152852199972\n",
      "2250 0.00133042037487\n",
      "2500 0.00117703096475\n",
      "2750 0.0010548470309\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# Depending on the initialization, this networks fails to train in about 10% cases.\n",
    "# We'll explain why during next lecture.\n",
    "params = [hWV, hbV, oWV, obV]\n",
    "\n",
    "for p in params:\n",
    "    p.data = torch.from_numpy(np.random.randn(*p.size()).astype('float32') * 0.1)\n",
    "\n",
    "for step in range(3000):\n",
    "    for p in params:\n",
    "        # functions ending in _ modify the tensor!\n",
    "        p.grad.data.zero_()\n",
    "    out = net(XV, *params)\n",
    "    loss = ((out - YV)**2).sum()\n",
    "    if (step % 250) == 0:\n",
    "        print(step, loss.data[0])\n",
    "    loss.backward()\n",
    "    for p in params:\n",
    "        p.data -= 1e-2 * p.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hWV,',\n",
      "  Variable containing:\n",
      " 0.4618  0.6597\n",
      " 0.4630  0.6651\n",
      "[torch.FloatTensor of size 2x2]\n",
      "),\n",
      " ('hbV,',\n",
      "  Variable containing:\n",
      "-0.7097 -0.2960\n",
      "[torch.FloatTensor of size 1x2]\n",
      "),\n",
      " ('oWV,',\n",
      "  Variable containing:\n",
      "-1.0539\n",
      " 0.9796\n",
      "[torch.FloatTensor of size 2x1]\n",
      "),\n",
      " ('obV', Variable containing:\n",
      "-0.4525\n",
      "[torch.FloatTensor of size 1x1]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(zip ('hWV, hbV, oWV, obV'.split(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    for p in params:\n",
    "        # functions ending in _ modify the tensor!\n",
    "        p.grad.data.zero_()\n",
    "    out = net(XV, *params)\n",
    "    loss = ((out - YV)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.00059986115\n",
      "250 0.999978721142\n",
      "500 0.999841153622\n",
      "750 0.997927606106\n",
      "1000 0.206064373255\n",
      "1250 0.0362930893898\n",
      "1500 0.0183573663235\n",
      "1750 0.0120765883476\n",
      "2000 0.0089367441833\n",
      "2250 0.00706796068698\n",
      "2500 0.00583356944844\n",
      "2750 0.00495963683352\n"
     ]
    }
   ],
   "source": [
    "# Alt network - this one is easier to train and converges most of the time!\n",
    "params = [hWV, hbV, oWV, obV]\n",
    "\n",
    "def net2(X, hW, hb, oW, ob):\n",
    "    H = torch.tanh(((X * 2.0 - 1.0).matmul(hW) + hb))\n",
    "    O = torch.sigmoid((H.matmul(oW) + ob))\n",
    "    return O\n",
    "\n",
    "for p in params:\n",
    "    p.data = torch.from_numpy(np.random.randn(*p.size()).astype('float32') * 0.1)\n",
    "\n",
    "for step in range(3000):\n",
    "    for p in params:\n",
    "        # functions ending in _ modify the tensor!\n",
    "        p.grad.data.zero_()\n",
    "    out = net2(XV, *params)\n",
    "    loss = ((out - YV)**2).sum()\n",
    "    if (step % 250) == 0:\n",
    "        print(step, loss.data[0])\n",
    "    loss.backward()\n",
    "    for p in params:\n",
    "        p.data -= p.grad.data * 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
