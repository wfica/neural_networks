{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks Fall lecture 02\n",
    "# Summary of the introductions.\n",
    "Machine learning (and deep learning and to some extent what is currently called AI) deals with making predictions based on a data set (sometimes also called a corpus): Data $\\longrightarrow$ Decision\n",
    "## We have seen 3 kinds of those problems:\n",
    "\n",
    "  1. Supervised learning  \n",
    "    Data point $\\longrightarrow$ answer  \n",
    "    image $\\longrightarrow$ 0,1,...,n (recognizing digitin an image)  \n",
    "    speech $\\longrightarrow$ \"thank you\" (transcription)  \n",
    "    \"Howdy\" $\\longrightarrow$ \"Siema\" (translation)  \n",
    "    In supervised learning the goal is to discover the relation between inputs \"X\" and targets \"Y\". What do we care about?  \n",
    "      * generalizing past the dataset\n",
    "      * doing well on new data\n",
    "      * having low error rate (expected value of missclassification) <br/><br/>\n",
    "      \n",
    "  2. Unsupervised learning.  \n",
    "    Possible uses:  \n",
    "      * generating more data\n",
    "      * describing the data\n",
    "      * recognizing if a new data point is similar to the data set <br/><br/>\n",
    "    \n",
    "  3. Reinforcement learning. With an environment to play with (game, life simulation etc.) we can answer questions like:  \n",
    "    * what to do to get high rewards?\n",
    "    * what is my expected reward?\n",
    "    * what actions should i try?  \n",
    "    \n",
    " We need a language to speak about our goals and objectives. The problems often involve a lot of uncertainty and we'll adopt the language of probability. \n",
    " * For supervised learning:   \n",
    "     We have data $ \\{ x^{(i)},y^{(i)}|i=1,\\dots ,N\\}\\sim P(X,Y) $ with $ f(x) $ such that $ f(x^i) \\approx y^i\\text{ for }i=1,\\dots,N $ in general we want to have large $\\mathbb{E}_{x,y\\sim P(x,y)}[f(x)=y]$ where $[x]$ is the indicator function ( $[True]=1\\text{, }[False]=0$ )\n",
    " * For unsupervised learning:  \n",
    "     We have $\\{x^{(i)}|i=1,\\dots,N\\}\\sim P(X)$ where we know $x^{(i)}$ but we dont know $P(X)$\n",
    " * For reinforcement learning:\n",
    "     We have a world with states $s$ and rewards $r(s)$. We pose such questions as: What is the expected value of my reward? Which probabilities to assign to my actions?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes example  \n",
    "  ### Data:\n",
    "$\\;\\;$ buy much now $\\longrightarrow$ spam  \n",
    "$\\;\\;$ much dollars gain $\\rightarrow$ spam  \n",
    "$\\;\\;$ like you much $\\rightarrow$ ham  \n",
    "$\\;\\;$ do your homework $\\rightarrow$ ham  \n",
    "$\\;\\;$ (ham is an important message as opposed to spam)\n",
    "  ### Expected result:\n",
    "$\\;\\;$ We want $P(\\text{spam }|\\text{ text})$. Will do instead $P(\\text{spam }|\\text{ text})=\\frac{P(\\text{text }|\\text{ spam})P(\\text{spam})}{P(\\text{text})}$\n",
    "  ### Model of data generation:\n",
    "$$ P(\\text{text }|\\text{ spam})=P(w_1|\\text{ spam})P(w_2|w_1,\\text{spam}) \\ldots \\approx[\\text{naive independence assumption}]\\approx P(w_1|\\text{ spam})P(w_2|\\text{ spam})\\dots $$\n",
    "$\\;\\;$ We have a model, now we must fit it to data.\n",
    "$$ P(\\text{data})=\\prod_{i=1}^N p(\\text{spam}^i) \\prod_{w\\in \\text{text}^i}p(w\\:|\\text{ spam}=\\text{spam}^i)$$\n",
    "$\\;\\;$ Where $N$ is total count of documents, $p(\\text{spam}^i)$ is probability of document i being spam and $p(w\\:|\\text{ spam}=\\text{spam}^i)$ is independent probability of words in $\\text{doc}^i$ given its class, $\\text{spam}^i$.  \n",
    "$\\;\\;$ We can fit the model using max likelihood.\n",
    "  ### Parameters:\n",
    "$$\\phi=p(\\text{spam}=\\text{True})\\:,\\;0\\leq\\phi\\leq 1$$  \n",
    "$$\\theta_{w,s}=p(w\\:|\\:\\text{spam}=\\text{True})\\:,\\;0\\leq\\theta_{w,s}\\leq 1\\;\\;\\sum_w\\theta_{w,s}=1$$\n",
    "$$\\theta_{w,h}=p(w\\:|\\:\\text{spam}=\\text{False})\\:,\\;0\\leq\\theta_{w,h}\\leq 1\\;\\;\\sum_w\\theta_{w,h}=1$$\n",
    "$\\;\\;$ By using Lagrange multipliers we can derive the Max Log Likelihood (MLL) solution for $\\phi,\\theta_{w,s},\\theta_{w,h}$\n",
    "$$\\phi=\\frac{\\#\\text{text is spam}}{\\#\\text{all texts}}=\\frac{\\sum_{i=1}^N[\\text{spam}^i=\\text{True}]}{N}$$\n",
    "$$\\theta_{w,s}=\\frac{\\#\\text{w appears in any spam}}{\\#\\text{all words in spam}}$$\n",
    "$\\;\\;$ In our example $\\phi=\\frac{2}{4}=\\frac{1}{2}$\n",
    "<TABLE>\n",
    "   <TR>\n",
    "      <TD>w</TD>\n",
    "      <TD>buy</TD>\n",
    "      <TD>much</TD>\n",
    "      <TD>now</TD>\n",
    "      <TD>dollars</TD>\n",
    "      <TD>gain</TD>\n",
    "      <TD>like</TD>\n",
    "      <TD>you/your</TD>\n",
    "      <TD>do</TD>\n",
    "      <TD>homework</TD>\n",
    "   </TR>\n",
    "   <TR>\n",
    "      <TD>spam</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{1}{3}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "   </TR>\n",
    "   <TR>\n",
    "      <TD>ham</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{0}{6}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{1}{3}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "      <TD>$\\frac{1}{6}$</TD>\n",
    "   </TR>\n",
    "</TABLE>  \n",
    "$p(\\text{spam }|\\text{ \"much much gain\"})=p(\\text{spam})\\cdot p(\\text{much }|\\text{ spam})\\cdot p(\\text{much }|\\text{ spam})\\cdot p(\\text{gain }|\\text{ spam})\\cdot\\frac{1}{p(\\text{text})}=\\frac{1}{2}\\cdot\\frac{1}{3}\\cdot\\frac{1}{3}\\cdot\\frac{1}{6}\\cdot 2=\\frac{1}{54}$ \n",
    "$p(\\text{ham }|\\text{ \"much much gain\"})=\\frac{1}{2}\\cdot\\frac{1}{6}\\cdot\\frac{1}{6}\\cdot\\frac{0}{6}\\cdot 2=0$  \n",
    "\n",
    "$\\;\\;$ The model assumes it is impossible to use word \"gain\" in a non-spam document. Solution to this is using Laplace pseudocounts, assuming each word from vocabulary occurs at least once in each text or each category. A few more practical problems:\n",
    "  * what about typos?\n",
    "  * what about new words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Naive Bayes MLE solution\n",
    "$$p(\\text{data})=\\prod_ip(\\text{spam}^{(i)},\\text{text}^{(i)}) = \\prod_{i=1}^N p(\\text{spam}^i) \\prod_{w\\in \\text{text}^i}p(w\\:|\\text{ spam}=\\text{spam}^i) = \\prod_i\\phi^{\\text{spam}^{(i)}}(1-\\phi)^{1-\\text{spam}^{(i)}}\\prod_{w\\in\\text{text}^{(i)}}\\theta_{w,s}^{spam^{(i)}}\\theta_{w,h}^{1-spam^{(i)}}$$  \n",
    "$\\;\\;$ Log. likelihood:\n",
    "\n",
    "$$\\log \\mathcal{L}(\\phi,\\theta)=\\sum_i[\\text{spam}^{(i)}\\log\\phi+(1-\\text{spam}^{(i)})\\log(1-\\phi)]+\\sum_i[\\sum_{w\\in\\text{text}^{i}}\\text{spam}^{(i)}\\log\\theta_{w,s}+\\sum_{w\\in\\text{text}^{i}}(1-\\text{spam}^{(i)})\\log\\theta_{w,h}]$$  \n",
    "$\\;\\;$ We'll maximize $\\log\\mathcal{L}$ subject to $\\sum_w\\theta_{w,s}=1,\\sum_w\\theta_{w,h}=1$  \n",
    "$\\;\\;$ Lagrangian:  \n",
    "$$L(\\phi,\\theta_{w,s},\\theta_{w,h},\\lambda_s,\\lambda_h)=\\log\\mathcal{L}(\\phi,\\theta)-\\lambda_s(\\sum_w\\theta_{w,s}-1)-\\lambda_h(\\sum_w\\theta_{w,h}-1)$$  \n",
    "$\\;\\;$ To find maximum we copute dervatives of the Lagrangian and solve the resulting system of equations.\n",
    "\n",
    "$$\\frac{\\delta L}{\\delta \\phi} = \\sum_i\\frac{\\text{spam}^{(i)}}{\\phi}-\\frac{1-\\text{spam}^{(i)}}{1-phi}=0 $$\n",
    "$$\\frac{\\delta L}{\\delta \\theta_{w,s}} = \\sum_{i:w\\in\\text{text}^{(i)}}|\\text{count of w in text i}|\\cdot\\text{spam}^{(i)}\\frac{1}{\\theta_{w,s}}-\\lambda_s \\;\\;\\forall_w$$\n",
    "$$\\frac{\\delta L}{\\delta \\lambda_s} \\sum_w\\theta_{w,s}-1=0 $$  \n",
    "$\\;\\;$ Derivatives for $\\theta_{w,h}$ and $\\lambda_h$ are analogous.  \n",
    "$\\;\\;$ Let's denote count of $w$ in text $i$ as $c_w^{(i)}$. Solving these equations we get: \n",
    "\n",
    "$$\\sum_i[\\text{spam}^{(i)}-\\phi\\text{spam}^{(i)}-\\phi+\\phi\\text{spam}^{(i)}]=0$$  \n",
    "$$\\sum_i\\text{spam}^{(i)}=\\phi\\sum_i1$$\n",
    "$$\\phi=\\frac{\\sum_i\\text{spam}^{(i)}}{\\sum_i1}=\\frac{\\#\\text{spams}}{\\#\\text{data}}$$\n",
    "$$\\begin{cases} \\forall_w\\sum_ic_w^{(i)}\\text{spam}^{(i)}\\frac{1}{\\theta_{w,s}}-\\lambda_s=0\\;\\;\\;\\;|\\cdot \\theta_{w,s} \\\\ \\sum_w\\theta_{w,s}=1  \\end{cases}$$  \n",
    "$$\\begin{cases} \\forall_w\\sum_ic_w^{(i)}\\text{spam}^{(i)}=\\theta_{w,s}\\lambda_s\\;\\;\\;\\;|\\text{sum all these} \\\\ \\sum_w\\theta_{w,s}=1  \\end{cases}$$  \n",
    "$$\\sum_w\\sum_ic_w^{(i)}\\text{spam}^{(i)}=\\lambda_s\\sum_w\\theta_{w,s}=\\lambda_s$$\n",
    "$$\\theta_{w,s}=\\frac{\\sum_i c_w^{(i)} \\text{spam}^{(i)}}{\\sum_w \\sum_i c_w^{(i)} \\text{spam}^{(i)}}=\\frac{\\#\\text{w appears in spam}}{\\#\\text{all words in spam}}$$  \n",
    "$\\;\\;$ $\\theta_{w,h}$ is derived in an analogous way.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27-test",
   "language": "python",
   "name": "py27-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
